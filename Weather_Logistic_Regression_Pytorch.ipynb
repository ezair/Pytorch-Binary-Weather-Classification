{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Weather Logistic Regression Pytorch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyZraRnomztn",
        "outputId": "a728b9cc-c931-48b8-bbdd-4059d05c7bc9"
      },
      "source": [
        "\"\"\"Constructed a NN model that performs binary weather classification to determine if it is going to\n",
        "rain or not. The test accuracy of the model is 100 percent accuracy\n",
        "(without use of a validation set). This model does not require the use of regularization/dropout.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Random seed for training/testing.\n",
        "RAND_SEED = 42\n",
        "random.seed(RAND_SEED)\n",
        "np.random.seed(RAND_SEED)\n",
        "torch.random.manual_seed(RAND_SEED)\n",
        "\n",
        "\n",
        "def get_cleaned_dataset(path_to_dataset):\n",
        "    df = pd.read_csv(path_to_dataset)\n",
        "\n",
        "    # Remove biased based features.\n",
        "    df = df.drop(\n",
        "        columns=[\n",
        "            \"Date\",\n",
        "            \"Location\",\n",
        "            \"RainTomorrow\",\n",
        "            \"Evaporation\",\n",
        "            \"Sunshine\",\n",
        "            \"WindGustDir\",\n",
        "            \"WindDir9am\",\n",
        "            \"WindDir3pm\",\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # Convert RainToday from string feature to interger feature with 1\n",
        "    # representing it will rain and 0 representing that it will not rain.\n",
        "    df[\"RainToday\"] = df[\"RainToday\"].replace([\"No\", \"Yes\"], [0, 1])\n",
        "\n",
        "    # Remove any record where a feature is na. There is enough data where\n",
        "    # we shouldn't bother replacing with the mean of the column.\n",
        "    df = df.dropna()\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_scaled_train_test_datasets(df):\n",
        "    # Split dataset into train/test.\n",
        "    # ...RainToday is our target vector.\n",
        "    y = df[[\"RainToday\"]]\n",
        "    X = df.drop(columns=[\"RainToday\"])\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=RAND_SEED, shuffle=True\n",
        "    )\n",
        "\n",
        "    # Scale input data to to make finding the gradient significantly faster.\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    \n",
        "    # Convert data to the form that pytorch requires (float32 tensors).\n",
        "    X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "    X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "    y_train = torch.from_numpy(y_train.to_numpy().astype(np.float32))\n",
        "    y_test = torch.from_numpy(y_test.to_numpy().astype(np.float32))\n",
        "\n",
        "    y_train = y_train.view(y_train.shape[0], 1)\n",
        "    y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "class Network(nn.Module):\n",
        "    \"\"\"NN for detecting if it is going to rain or not.\n",
        "    This network is strictly used for binary classification.\n",
        "    Effectively what we are doing is Logistic Regression with\n",
        "    no regularization. This NN has 1 input layer, 2 hidden, and one output.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.hidden = nn.Linear(input_size, input_size)\n",
        "        self.hidden2 = nn.Linear(input_size, input_size)\n",
        "        self.output = nn.Linear(input_size, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden(x)  \n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.hidden2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.output(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Set training device.\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Get dataset.\n",
        "    weather_dataset_url = '/content/rain.csv'\n",
        "    X_train, X_test, y_train, y_test = get_scaled_train_test_datasets(\n",
        "        get_cleaned_dataset(path_to_dataset=weather_dataset_url)\n",
        "    )\n",
        "\n",
        "    # Decide input and output size for NN.\n",
        "    # ...input size is the number of features (Columns in X_train/X_test).\n",
        "    # ... output size is 1 because we are doing logistic regression.\n",
        "    input_size = X_train.shape[1]\n",
        "\n",
        "    # Set hyper params for NN.\n",
        "    learning_rate = 0.01\n",
        "    number_of_epochs = 190\n",
        "\n",
        "    # Create network.\n",
        "    model = Network(input_size=input_size).to(device)\n",
        "\n",
        "    # Set loss function.\n",
        "    loss_function = nn.BCELoss()\n",
        "\n",
        "    # Set optimization function for finding gradient.\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Train network.\n",
        "    for epoch in range(number_of_epochs):\n",
        "        # Forward pass and loss calculation.\n",
        "        y_predicted = model(X_train)\n",
        "        loss = loss_function(y_predicted, y_train)\n",
        "\n",
        "        # Backwards propagation pass.\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Zero-out/empty gradients before next iteration.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Display the loss of the function every 10 steps.\n",
        "        if epoch + 1 % 10 == 0:\n",
        "            print(f\"epoch: {epoch + 1}, loss = {loss.item():.4f}\")\n",
        "\n",
        "    # Test model and get accuracy.\n",
        "    with torch.no_grad():\n",
        "        # Get accuracy of model.\n",
        "        # ... To determine if something is class 1, we will simply use 0.5\n",
        "        # as the cutoff point for our Logistic Regression.\n",
        "        y_predicted = model(X_test)\n",
        "        y_predicted_classes = y_predicted.round()\n",
        "        accuracy = y_predicted_classes.eq(y_test).sum() / float(y_test.shape[0])\n",
        "        print(f\"Model accuracy: {accuracy:.4f}\")\n",
        "    \n",
        "    # Save the model now that testing is complete.\n",
        "    torch.save(model, f=os.path.join(os.getcwd(), 'model.pt'))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLPLvBwT2p-A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}